{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "etest_data = pd.read_csv(\"data/etest.csv\")\n",
    "etrain_data = pd.read_csv(\"data/etrain.csv\")\n",
    "eval_data = pd.read_csv(\"data/evalidation.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "val_data = pd.read_csv(\"data/validation.csv\")\n",
    "numeric_features = np.load('numeric_features.npy')\n",
    "selected_features = np.load('selected_features.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_num=[]\n",
    "for i in etest_data.columns:\n",
    "    if(i not in numeric_features and i != 'target'):\n",
    "        not_num.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "etest_data_t = etest_data.drop(['target'],axis = 1)\n",
    "etrain_data_t = etrain_data.drop(['target'],axis = 1)\n",
    "eval_data_t = eval_data.drop(['target'],axis = 1)\n",
    "n_etest_data_t = etest_data.drop(['target'],axis = 1).loc[:,numeric_features]\n",
    "n_etrain_data_t = etrain_data.drop(['target'],axis = 1).loc[:,numeric_features]\n",
    "n_eval_data_t = eval_data.drop(['target'],axis = 1).loc[:,numeric_features]\n",
    "nn_etest_data_t = etest_data.drop(['target'],axis = 1).loc[:,not_num]\n",
    "nn_etrain_data_t = etrain_data.drop(['target'],axis = 1).loc[:,not_num]\n",
    "nn_eval_data_t = eval_data.drop(['target'],axis = 1).loc[:,not_num]\n",
    "sf_etest_data_t = etest_data.drop(['target'],axis = 1).loc[:,selected_features]\n",
    "sf_etrain_data_t = etrain_data.drop(['target'],axis = 1).loc[:,selected_features]\n",
    "sf_eval_data_t = eval_data.drop(['target'],axis = 1).loc[:,selected_features]\n",
    "etrain_data_target = etrain_data[[\"target\"]]\n",
    "etest_data_target = etest_data[[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name_1 = [\"Mix feature\",\"Only use numeric features\",\"Only use category features\"]\n",
    "train_data_name_1 = [etrain_data_t,n_etrain_data_t,nn_etrain_data_t,sf_etrain_data_t]\n",
    "test_data_name_1 = [etest_data_t,n_etest_data_t,nn_etest_data_t,sf_etest_data_t]\n",
    "dataset_name_2 = [\"Selected mix feature\",\"Only use numeric features\",\"Only use category features\"]\n",
    "train_data_name_2 = [sf_etrain_data_t,n_etrain_data_t,nn_etrain_data_t]\n",
    "test_data_name_2 = [sf_etest_data_t,n_etest_data_t,nn_etest_data_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal(i,result):\n",
    "    f_score = 0\n",
    "    accuracy = 0\n",
    "    total = len(etest_data_target)\n",
    "    for temp in result:\n",
    "        f_score += temp['weighted avg']['f1-score'] * (temp['weighted avg']['support'] / total)\n",
    "        accuracy += temp['accuracy'] * (temp['weighted avg']['support'] / total)\n",
    "    return f_score,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mix feature\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.64      0.57      2051\n",
      "           1       0.38      0.37      0.38      2090\n",
      "           2       0.38      0.37      0.37      2110\n",
      "           3       0.68      0.56      0.61      2058\n",
      "\n",
      "    accuracy                           0.48      8309\n",
      "   macro avg       0.49      0.48      0.48      8309\n",
      "weighted avg       0.49      0.48      0.48      8309\n",
      "\n",
      "f_score: 0.482710  accuracy: 0.483331 \n",
      "==========================================================\n",
      "Only use numeric features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.78      0.66      2051\n",
      "           1       0.41      0.41      0.41      2090\n",
      "           2       0.45      0.42      0.44      2110\n",
      "           3       0.84      0.59      0.69      2058\n",
      "\n",
      "    accuracy                           0.55      8309\n",
      "   macro avg       0.57      0.55      0.55      8309\n",
      "weighted avg       0.57      0.55      0.55      8309\n",
      "\n",
      "f_score: 0.547439  accuracy: 0.548321 \n",
      "==========================================================\n",
      "Only use category features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.56      0.52      2051\n",
      "           1       0.35      0.31      0.33      2090\n",
      "           2       0.33      0.33      0.33      2110\n",
      "           3       0.54      0.52      0.53      2058\n",
      "\n",
      "    accuracy                           0.43      8309\n",
      "   macro avg       0.43      0.43      0.43      8309\n",
      "weighted avg       0.43      0.43      0.43      8309\n",
      "\n",
      "f_score: 0.426250  accuracy: 0.428451 \n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=4)\n",
    "for i in range (len(dataset_name_1)):  \n",
    "    print(dataset_name_1[i])\n",
    "    result = []\n",
    "    classifier.fit(train_data_name_1[i], etrain_data_target.values.ravel())\n",
    "    y_pred = classifier.predict(test_data_name_1[i])\n",
    "    print(classification_report(etest_data_target, y_pred))\n",
    "    result.append(classification_report(etest_data_target, y_pred, zero_division=True, output_dict=True))\n",
    "    print(\"f_score: %f  accuracy: %f \" %cal(i,result))\n",
    "    print('==========================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected mix feature\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.71      0.59      2051\n",
      "           1       0.38      0.37      0.37      2090\n",
      "           2       0.40      0.37      0.38      2110\n",
      "           3       0.75      0.53      0.63      2058\n",
      "\n",
      "    accuracy                           0.49      8309\n",
      "   macro avg       0.51      0.50      0.49      8309\n",
      "weighted avg       0.51      0.49      0.49      8309\n",
      "\n",
      "f_score: 0.491831  accuracy: 0.493682 \n",
      "==========================================================\n",
      "Only use numeric features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.78      0.66      2051\n",
      "           1       0.41      0.41      0.41      2090\n",
      "           2       0.45      0.42      0.44      2110\n",
      "           3       0.84      0.59      0.69      2058\n",
      "\n",
      "    accuracy                           0.55      8309\n",
      "   macro avg       0.57      0.55      0.55      8309\n",
      "weighted avg       0.57      0.55      0.55      8309\n",
      "\n",
      "f_score: 0.547439  accuracy: 0.548321 \n",
      "==========================================================\n",
      "Only use category features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.56      0.52      2051\n",
      "           1       0.35      0.31      0.33      2090\n",
      "           2       0.33      0.33      0.33      2110\n",
      "           3       0.54      0.52      0.53      2058\n",
      "\n",
      "    accuracy                           0.43      8309\n",
      "   macro avg       0.43      0.43      0.43      8309\n",
      "weighted avg       0.43      0.43      0.43      8309\n",
      "\n",
      "f_score: 0.426250  accuracy: 0.428451 \n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=4)\n",
    "for i in range (len(dataset_name_2)):  \n",
    "    print(dataset_name_2[i])\n",
    "    result = []\n",
    "    classifier.fit(train_data_name_2[i], etrain_data_target.values.ravel())\n",
    "    y_pred = classifier.predict(test_data_name_2[i])\n",
    "    print(classification_report(etest_data_target, y_pred))\n",
    "    result.append(classification_report(etest_data_target, y_pred, zero_division=True, output_dict=True))\n",
    "    print(\"f_score: %f  accuracy: %f \" %cal(i,result))\n",
    "    print('==========================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mix feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mix feature\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.55      0.55      2051\n",
      "           1       0.37      0.30      0.33      2090\n",
      "           2       0.38      0.35      0.36      2110\n",
      "           3       0.57      0.74      0.65      2058\n",
      "\n",
      "    accuracy                           0.48      8309\n",
      "   macro avg       0.47      0.48      0.47      8309\n",
      "weighted avg       0.47      0.48      0.47      8309\n",
      "\n",
      "f_score: 0.472468  accuracy: 0.483091 \n",
      "==========================================================\n",
      "Only use numeric features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.67      0.61      2051\n",
      "           1       0.44      0.43      0.43      2090\n",
      "           2       0.48      0.46      0.47      2110\n",
      "           3       0.79      0.71      0.75      2058\n",
      "\n",
      "    accuracy                           0.56      8309\n",
      "   macro avg       0.57      0.57      0.57      8309\n",
      "weighted avg       0.57      0.56      0.56      8309\n",
      "\n",
      "f_score: 0.564049  accuracy: 0.563726 \n",
      "==========================================================\n",
      "Only use category features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.54      0.54      2051\n",
      "           1       0.36      0.29      0.32      2090\n",
      "           2       0.36      0.31      0.33      2110\n",
      "           3       0.52      0.70      0.60      2058\n",
      "\n",
      "    accuracy                           0.46      8309\n",
      "   macro avg       0.45      0.46      0.45      8309\n",
      "weighted avg       0.45      0.46      0.45      8309\n",
      "\n",
      "f_score: 0.447208  accuracy: 0.459502 \n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "model = NearestCentroid() \n",
    "for i in range (len(dataset_name_1)): \n",
    "    print(dataset_name_1[i])\n",
    "    result = []\n",
    "    model.fit(train_data_name_1[i], etrain_data_target.values.ravel())\n",
    "    y_pred = model.predict(test_data_name_1[i])\n",
    "    print(classification_report(etest_data_target, y_pred))\n",
    "    result.append(classification_report(etest_data_target, y_pred, zero_division=True, output_dict=True))\n",
    "    print(\"f_score: %f  accuracy: %f \" %cal(i,result))\n",
    "    print('==========================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected mix feature\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.57      0.56      2051\n",
      "           1       0.37      0.26      0.31      2090\n",
      "           2       0.37      0.36      0.36      2110\n",
      "           3       0.58      0.75      0.66      2058\n",
      "\n",
      "    accuracy                           0.48      8309\n",
      "   macro avg       0.47      0.48      0.47      8309\n",
      "weighted avg       0.47      0.48      0.47      8309\n",
      "\n",
      "f_score: 0.469644  accuracy: 0.483211 \n",
      "==========================================================\n",
      "Only use numeric features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.67      0.61      2051\n",
      "           1       0.44      0.43      0.43      2090\n",
      "           2       0.48      0.46      0.47      2110\n",
      "           3       0.79      0.71      0.75      2058\n",
      "\n",
      "    accuracy                           0.56      8309\n",
      "   macro avg       0.57      0.57      0.57      8309\n",
      "weighted avg       0.57      0.56      0.56      8309\n",
      "\n",
      "f_score: 0.564049  accuracy: 0.563726 \n",
      "==========================================================\n",
      "Only use category features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.54      0.54      2051\n",
      "           1       0.36      0.29      0.32      2090\n",
      "           2       0.36      0.31      0.33      2110\n",
      "           3       0.52      0.70      0.60      2058\n",
      "\n",
      "    accuracy                           0.46      8309\n",
      "   macro avg       0.45      0.46      0.45      8309\n",
      "weighted avg       0.45      0.46      0.45      8309\n",
      "\n",
      "f_score: 0.447208  accuracy: 0.459502 \n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "model = NearestCentroid() \n",
    "for i in range (len(dataset_name_2)): \n",
    "    print(dataset_name_2[i])\n",
    "    result = []\n",
    "    model.fit(train_data_name_2[i], etrain_data_target.values.ravel())\n",
    "    y_pred = model.predict(test_data_name_2[i])\n",
    "    print(classification_report(etest_data_target, y_pred))\n",
    "    result.append(classification_report(etest_data_target, y_pred, zero_division=True, output_dict=True))\n",
    "    print(\"f_score: %f  accuracy: %f \" %cal(i,result))\n",
    "    print('==========================================================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
